{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f920898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.5-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting neattext\n",
      "  Using cached neattext-0.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\dsa\\text emotion detect\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Using cached matplotlib-3.10.3-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached fonttools-4.58.0-cp313-cp313-win_amd64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\dsa\\text emotion detect\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in e:\\dsa\\text emotion detect\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "Using cached numpy-2.2.5-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "Using cached neattext-0.1.3-py3-none-any.whl (114 kB)\n",
      "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Using cached matplotlib-3.10.3-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.2-cp313-cp313-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.2.1-cp313-cp313-win_amd64.whl (2.7 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.15.3-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, pyparsing, pillow, numpy, neattext, kiwisolver, joblib, fonttools, cycler, scipy, pandas, contourpy, scikit-learn, matplotlib, seaborn\n",
      "\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   ----------------------------------------  0/17 [pytz]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   -- -------------------------------------  1/17 [tzdata]\n",
      "   ------- --------------------------------  3/17 [pyparsing]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   --------- ------------------------------  4/17 [pillow]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   ----------- ----------------------------  5/17 [numpy]\n",
      "   -------------- -------------------------  6/17 [neattext]\n",
      "   ------------------ ---------------------  8/17 [joblib]\n",
      "   ------------------ ---------------------  8/17 [joblib]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   --------------------- ------------------  9/17 [fonttools]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ------------------------- -------------- 11/17 [scipy]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   ---------------------------- ----------- 12/17 [pandas]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   -------------------------------- ------- 14/17 [scikit-learn]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ----------------------------------- ---- 15/17 [matplotlib]\n",
      "   ------------------------------------- -- 16/17 [seaborn]\n",
      "   ------------------------------------- -- 16/17 [seaborn]\n",
      "   ---------------------------------------- 17/17 [seaborn]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 joblib-1.5.0 kiwisolver-1.4.8 matplotlib-3.10.3 neattext-0.1.3 numpy-2.2.5 pandas-2.2.3 pillow-11.2.1 pyparsing-3.2.3 pytz-2025.2 scikit-learn-1.6.1 scipy-1.15.3 seaborn-0.13.2 threadpoolctl-3.6.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy seaborn scikit-learn neattext joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691c5554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6210\n",
      "SVM Accuracy: 0.6154\n",
      "Random Forest Accuracy: 0.5821\n",
      "Best Model: Logistic Regression (Accuracy: 0.6210)\n",
      "Prediction: joy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Logistic Regression', 'joy')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEXT EMOTION DETECTION with Multiple Model Comparison and Proper Model Saving/Loading\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import neattext.functions as nfx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset (update path if needed)\n",
    "df = pd.read_csv(\"data/emotion_dataset_raw.csv\")\n",
    "\n",
    "\n",
    "# Clean the text data\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles).apply(nfx.remove_stopwords)\n",
    "\n",
    "# Features and labels\n",
    "X = df['Clean_Text']\n",
    "y = df['Emotion']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the model pipelines\n",
    "pipelines = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('cv', CountVectorizer()),\n",
    "        ('lr', LogisticRegression(max_iter=1000))\n",
    "    ]),\n",
    "    \"SVM\": Pipeline([\n",
    "        ('cv', CountVectorizer()),\n",
    "        ('svc', SVC(probability=True))\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        ('cv', CountVectorizer()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train all models and evaluate accuracy\n",
    "model_scores = {}\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    acc = pipe.score(X_test, y_test)\n",
    "    model_scores[name] = (pipe, acc)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save the trained models\n",
    "for name, (model, _) in model_scores.items():\n",
    "    filename = os.path.join(MODEL_DIR, f\"pipe_{name.lower().replace(' ', '_')}.pkl\")\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "# Function to load models (optional)\n",
    "def load_models(model_dir=MODEL_DIR):\n",
    "    loaded_models = {}\n",
    "    for file in os.listdir(model_dir):\n",
    "        if file.endswith(\".pkl\"):\n",
    "            model_name = file.replace(\"pipe_\", \"\").replace(\".pkl\", \"\").replace(\"_\", \" \").title()\n",
    "            loaded_models[model_name] = joblib.load(os.path.join(model_dir, file))\n",
    "    return loaded_models\n",
    "\n",
    "# Load models back if needed\n",
    "# loaded_models = load_models()\n",
    "\n",
    "# Use the already trained models and accuracies for prediction\n",
    "def predict_best_model(text):\n",
    "    # Select the best model by accuracy\n",
    "    best_model_name = max(model_scores, key=lambda k: model_scores[k][1])\n",
    "    best_model, best_acc = model_scores[best_model_name]\n",
    "    prediction = best_model.predict([text])[0]\n",
    "    print(f\"Best Model: {best_model_name} (Accuracy: {best_acc:.4f})\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    return best_model_name, prediction\n",
    "\n",
    "# Test the prediction function\n",
    "predict_best_model(\"I am feeling very happy today!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
